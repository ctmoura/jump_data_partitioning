{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Experimentos.csv')\n",
    "\n",
    "# Normaliza a coluna removendo o %\n",
    "df[\"Uso Máx. CPU\"] = df[\"Uso Máx. CPU\"].astype(str).str.replace(\"%\", \"\")\n",
    "\n",
    "# Convertendo colunas numéricas (e substituir vírgula decimal por ponto)\n",
    "numeric_columns = [\n",
    "    \"Nº Usuários\", \"Taxa Erros (%)\", \"Menor Duração\", \"Maior Duração\", \"Duração Média\", \"Conexões Ativas\",\n",
    "    \"Tam. Arq. Temp. (GB)\", \"Cache Hit (%)\", \"Uso Máx. CPU\", \"Uso Máx. Memória (GB)\"\n",
    "]\n",
    "for col in numeric_columns:\n",
    "    df[col] = df[col].astype(str).str.replace(\",\", \".\").astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeira abordagem\n",
    "\n",
    "Você deve mudar os pesos de acordo com o seu conhecimento na área"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking dos Experimentos (melhor desempenho):\n",
      "  Experimento     Score\n",
      "3      Exp_03  5.296965\n",
      "4      Exp_04  5.240595\n",
      "1      Exp_01  5.152517\n",
      "2      Exp_02  5.099420\n",
      "0      Exp_00  4.280034\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Função de normalização\n",
    "def normalize(series, invert=False):\n",
    "    min_val = series.min()\n",
    "    max_val = series.max()\n",
    "    norm = (series - min_val) / (max_val - min_val)\n",
    "    return 1 - norm if invert else norm\n",
    "\n",
    "# Vamos definir os pesos para cada métrica (ajuste conforme a importância)\n",
    "pesos = {\n",
    "    \"Nº Usuários\": 2.0,                 # Quanto maior número de usuários, melhor\n",
    "    \"Taxa Erros (%)\": -1.0,             # Quanto menor a taxa de erros, melhor\n",
    "    \"Menor Duração\": -1.0,              # Quanto menor a duração média, melhor\n",
    "    \"Maior Duração\": -1.0,              # Quanto menor a duração máxima é melhor\n",
    "    \"Duração Média\": -2.0,              # Quanto menor a duração média é melhor\n",
    "    \"Conexões Ativas\": -1.0,            # Quanto menos conexoes ativas é melhor\n",
    "    \"Tam. Arq. Temp. (GB)\": -1.0,       # Quanto menos arquivo temporario é melhor\n",
    "    \"Cache Hit (%)\": 1.0,               # Quanto maior uso da cache é melhor\n",
    "    \"Uso Máx. CPU\": -1.0,               # Quanto menos uso de CPU é melhor\n",
    "    \"Uso Máx. Memória (GB)\": -2.0       # Quanto menos uso de memória é melhor\n",
    "}\n",
    "\n",
    "# Normalizando e aplicando os pesos\n",
    "df_norm = pd.DataFrame()\n",
    "\n",
    "# Normalizar \"Nº Usuários\" (quanto maior, melhor)\n",
    "df_norm[\"Nº Usuários\"] = normalize(df[\"Nº Usuários\"]) * pesos[\"Nº Usuários\"]\n",
    "\n",
    "# Normalizar \"Taxa Erros (%)\" (quanto menor, melhor)\n",
    "df_norm[\"Taxa Erros (%)\"] = normalize(df[\"Taxa Erros (%)\"], invert=True) * pesos[\"Taxa Erros (%)\"]\n",
    "\n",
    "# Normalizar \"Menor Duração\" (quanto menor, melhor)\n",
    "df_norm[\"Menor Duração\"] = normalize(df[\"Menor Duração\"], invert=True) * pesos[\"Menor Duração\"]\n",
    "\n",
    "# Normalizar \"Maior Duração\" (quanto menor, melhor)\n",
    "df_norm[\"Maior Duração\"] = normalize(df[\"Maior Duração\"], invert=True) * pesos[\"Maior Duração\"]\n",
    "\n",
    "# Normalizar \"Duração Média\" (quanto menor, melhor)\n",
    "df_norm[\"Duração Média\"] = normalize(df[\"Duração Média\"], invert=True) * pesos[\"Duração Média\"]\n",
    "\n",
    "# Normalizar \"Conexões Ativas\" (quanto menor, melhor)\n",
    "df_norm[\"Conexões Ativas\"] = normalize(df[\"Conexões Ativas\"], invert=True) * pesos[\"Conexões Ativas\"]\n",
    "\n",
    "# Normalizar \"Tam. Arq. Temp. (GB)\" (quanto menor, melhor)\n",
    "df_norm[\"Tam. Arq. Temp. (GB)\"] = normalize(df[\"Tam. Arq. Temp. (GB)\"], invert=True) * pesos[\"Tam. Arq. Temp. (GB)\"]\n",
    "\n",
    "# Normalizar \"Cache Hit (%)\" (quanto maior, melhor)\n",
    "df_norm[\"Cache Hit (%)\"] = normalize(df[\"Cache Hit (%)\"]) * pesos[\"Cache Hit (%)\"]\n",
    "\n",
    "# Normalizar \"Uso Máx. CPU\" (quanto menor, melhor)\n",
    "df_norm[\"Uso Máx. CPU\"] = normalize(df[\"Uso Máx. CPU\"], invert=True) * pesos[\"Uso Máx. CPU\"]\n",
    "\n",
    "# Normalizar \"Uso Máx. Memória (GB)\" (quanto menor, melhor)\n",
    "df_norm[\"Uso Máx. Memória (GB)\"] = normalize(df[\"Uso Máx. Memória (GB)\"], invert=True) * pesos[\"Uso Máx. Memória (GB)\"]\n",
    "\n",
    "# Calcular o score composto somando as métricas ponderadas\n",
    "df_norm[\"Score\"] = df_norm.sum(axis=1) * -1\n",
    "\n",
    "# Adicionar coluna de Experimento para facilitar o agrupamento (se houver mais de um por experimento)\n",
    "df_norm[\"Experimento\"] = df[\"Experimento\"]\n",
    "\n",
    "# Se houver múltiplas linhas por experimento, podemos tirar a média do score\n",
    "df_result = df_norm.groupby(\"Experimento\")[\"Score\"].mean().reset_index()\n",
    "\n",
    "# Ordenar do melhor para o pior (quanto maior o score, melhor o desempenho)\n",
    "df_result = df_result.sort_values(by=\"Score\", ascending=False)\n",
    "\n",
    "print(\"Ranking dos Experimentos (melhor desempenho):\")\n",
    "print(df_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segunda Abordagem\n",
    "\n",
    "Você deve mudar os pesos de acordo com o seu conhecimento na área"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking dos Experimentos (por mediana):\n",
      "  Experimento  TOPSIS Score\n",
      "0      Exp_03      0.827700\n",
      "1      Exp_04      0.826417\n",
      "2      Exp_02      0.802033\n",
      "3      Exp_01      0.801455\n",
      "4      Exp_00      0.647560\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carrega o DataFrame\n",
    "df = pd.read_csv('Experimentos.csv')\n",
    "\n",
    "# Normaliza a coluna removendo o %\n",
    "df[\"Uso Máx. CPU\"] = df[\"Uso Máx. CPU\"].astype(str).str.replace(\"%\", \"\")\n",
    "\n",
    "# Convertendo colunas numéricas (e substituir vírgula decimal por ponto)\n",
    "numeric_columns = [\n",
    "    \"Nº Usuários\", \"Taxa Erros (%)\", \"Menor Duração\", \"Maior Duração\", \"Duração Média\", \"Conexões Ativas\",\n",
    "    \"Tam. Arq. Temp. (GB)\", \"Cache Hit (%)\", \"Uso Máx. CPU\", \"Uso Máx. Memória (GB)\"\n",
    "]\n",
    "for col in numeric_columns:\n",
    "    df[col] = df[col].astype(str).str.replace(\",\", \".\").astype(float)\n",
    "# Exemplo de colunas utilizadas:\n",
    "# \"Experimento\", \"Nº Usuários\", \"Taxa Erros (%)\", \"Menor Duração\", \"Maior Duração\", \"Cache Hit (%)\"\n",
    "\n",
    "# Vamos definir os critérios a usar e se cada um é de benefício (True) ou de custo (False)\n",
    "criteria_info = {\n",
    "    \"Nº Usuários\": True,                 # Quanto maior número de usuários, melhor\n",
    "    \"Taxa Erros (%)\": False,             # Quanto menor a taxa de erros, melhor\n",
    "    \"Menor Duração\": False,              # Quanto menor a duração média, melhor\n",
    "    \"Maior Duração\": False,              # Quanto menor a duração máxima é melhor\n",
    "    \"Duração Média\": False,              # Quanto menor a duração média é melhor\n",
    "    \"Conexões Ativas\": False,            # Quanto menos conexoes ativas é melhor\n",
    "    \"Tam. Arq. Temp. (GB)\": False,       # Quanto menos arquivo temporario é melhor\n",
    "    \"Cache Hit (%)\": True,               # Quanto maior uso da cache é melhor\n",
    "    \"Uso Máx. CPU\": False,               # Quanto menos uso de CPU é melhor\n",
    "    \"Uso Máx. Memória (GB)\": False       # Quanto menos uso de memória é melhor\n",
    "}\n",
    "\n",
    "# Definir os pesos para cada critério (importância relativa)\n",
    "# Ajuste os valores conforme sua análise fundamentada\n",
    "weights = {\n",
    "    \"Nº Usuários\": 1.0,                 # Quanto maior número de usuários, melhor\n",
    "    \"Taxa Erros (%)\": -0.5,             # Quanto menor a taxa de erros, melhor\n",
    "    \"Menor Duração\": -0.5,              # Quanto menor a duração média, melhor\n",
    "    \"Maior Duração\": -0.5,              # Quanto menor a duração máxima é melhor\n",
    "    \"Duração Média\": -1.0,              # Quanto menor a duração média é melhor\n",
    "    \"Conexões Ativas\": -0.5,            # Quanto menos conexoes ativas é melhor\n",
    "    \"Tam. Arq. Temp. (GB)\": -0.5,       # Quanto menos arquivo temporario é melhor\n",
    "    \"Cache Hit (%)\": 0.5,               # Quanto maior uso da cache é melhor\n",
    "    \"Uso Máx. CPU\": -0.5,               # Quanto menos uso de CPU é melhor\n",
    "    \"Uso Máx. Memória (GB)\": -0.5       # Quanto menos uso de memória é melhor\n",
    "}\n",
    "\n",
    "# Normalizando os pesos para que a soma seja 1\n",
    "total_weight = sum(weights.values())\n",
    "for crit in weights:\n",
    "    weights[crit] /= total_weight\n",
    "\n",
    "# Seleciona apenas as colunas de critérios\n",
    "criteria_cols = list(criteria_info.keys())\n",
    "decision_matrix = df[criteria_cols].astype(float).copy()\n",
    "\n",
    "# 1. Normalização da matriz de decisão (normalização Euclidiana)\n",
    "norm_decision = decision_matrix.copy()\n",
    "for crit in criteria_cols:\n",
    "    norm = np.sqrt((decision_matrix[crit]**2).sum())\n",
    "    norm_decision[crit] = decision_matrix[crit] / norm\n",
    "\n",
    "# 2. Multiplicar pelos pesos\n",
    "weighted_matrix = norm_decision.copy()\n",
    "for crit in criteria_cols:\n",
    "    weighted_matrix[crit] = weighted_matrix[crit] * weights[crit]\n",
    "\n",
    "# 3. Determinar as soluções ideais positiva e negativa\n",
    "ideal_positive = {}\n",
    "ideal_negative = {}\n",
    "for crit in criteria_cols:\n",
    "    if criteria_info[crit]:  # Critério de benefício\n",
    "        ideal_positive[crit] = weighted_matrix[crit].max()\n",
    "        ideal_negative[crit] = weighted_matrix[crit].min()\n",
    "    else:  # Critério de custo\n",
    "        ideal_positive[crit] = weighted_matrix[crit].min()\n",
    "        ideal_negative[crit] = weighted_matrix[crit].max()\n",
    "\n",
    "# 4. Calcular as distâncias Euclidianas para cada alternativa\n",
    "def euclidean_distance(row, ideal):\n",
    "    return np.sqrt(np.sum((row - ideal) ** 2))\n",
    "\n",
    "# Converter soluções ideais para Series para facilitar o cálculo\n",
    "ideal_positive_series = pd.Series(ideal_positive)\n",
    "ideal_negative_series = pd.Series(ideal_negative)\n",
    "\n",
    "# Inicializa listas para armazenar as distâncias\n",
    "dist_pos = []\n",
    "dist_neg = []\n",
    "\n",
    "for index, row in weighted_matrix.iterrows():\n",
    "    d_pos = euclidean_distance(row, ideal_positive_series)\n",
    "    d_neg = euclidean_distance(row, ideal_negative_series)\n",
    "    dist_pos.append(d_pos)\n",
    "    dist_neg.append(d_neg)\n",
    "\n",
    "# 5. Calcular o coeficiente de similaridade (TOPSIS score)\n",
    "topsis_score = []\n",
    "for d_pos, d_neg in zip(dist_pos, dist_neg):\n",
    "    score = d_neg / (d_pos + d_neg)\n",
    "    topsis_score.append(score)\n",
    "\n",
    "# 6. Criar um DataFrame com os resultados e ordenar\n",
    "df_topsis = pd.DataFrame({\n",
    "    \"Experimento\": df[\"Experimento\"],\n",
    "    \"TOPSIS Score\": topsis_score\n",
    "})\n",
    "df_topsis = df_topsis.sort_values(by=\"TOPSIS Score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_topsis_unique = df_topsis.groupby(\"Experimento\", as_index=False)[\"TOPSIS Score\"].median()\n",
    "df_topsis_unique = df_topsis_unique.sort_values(by=\"TOPSIS Score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Ranking dos Experimentos (por mediana):\")\n",
    "print(df_topsis_unique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "comparar as duas abordagens comparando os resultados , é bom chamar atenção que o topsis é um método já consolidado.\n",
    "\n",
    "Dizer que o primeiro método foi criado com base na sua experiência e feeling da área e que o segundo foi usado para comparar com uma abordagem já consolidada.\n",
    "\n",
    "é bom destacar que nos dois casos os experimentos 4 e 3 ficaram próximas em nos primeiros lugares. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
